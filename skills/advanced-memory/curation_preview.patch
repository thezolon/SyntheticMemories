--- a/MEMORY.md
+++ b/MEMORY.md
@@ -24,3 +24,27 @@
 - [ ] **Fix the memory system created yesterday morning** (user request from 2026-02-02)
   - Review implementation
   - Address any issues or improvements needed
+
+---
+
+## System & Hardware
+
+- 2026-02-01 — System has dual NVIDIA GeForce RTX 5060 Ti GPUs with 16GB VRAM each (32GB total GPU memory) (importance: 8) [source: advanced-memory:mem_1769957830208]
+- 2026-02-01 — CPU: AMD Ryzen 9 9900X3D 12-Core (24 threads), 91GB system RAM (importance: 8) [source: advanced-memory:mem_1769957830225]
+- 2026-02-01 — User's system is accessible at 192.168.2.22 from external machines, not localhost (importance: 7) [source: advanced-memory:mem_1769957402688]
+
+## AI/ML Infrastructure
+
+- 2026-02-01 — Ollama is running on both GPUs with 80+ models available locally, including large models up to 87GB (MiniMax-M2.1-REAP-30) (importance: 8) [source: advanced-memory:mem_1769957830242]
+- 2026-02-01 — Current embedding model: nomic-embed-text (274MB), but larger embeddings available like snowflake-arctic-embed-m-long and mxbai-embed-large (importance: 7) [source: advanced-memory:mem_1769957830259]
+- 2026-02-01 — System has multiple uncensored/creative models for generating descriptions: stheno-v3.2, darkidol, mythomax, ninja-v3 (importance: 7) [source: advanced-memory:mem_1769957830275]
+
+## Advanced Memory Skill
+
+- 2026-02-01 — Built advanced-memory skill with LanceDB vector database and Ollama embeddings for semantic memory search (importance: 8) [source: advanced-memory:mem_1769957402622]
+- 2026-02-01 — Created web UI for advanced-memory at port 8768 with dark theme, semantic search, filters, and add memory modal (importance: 8) [source: advanced-memory:mem_1769957402657]
+- 2026-02-01 — Fixed LanceDB Float32 type error by using PyArrow schema with explicit float32 vector type definition (importance: 7) [source: advanced-memory:mem_1769957402641]
+- 2026-02-01 — Advanced-memory skill lives at ~/.openclaw/workspace/skills/advanced-memory and survives OpenClaw updates (importance: 7) [source: advanced-memory:mem_1769957402673]
+- 2026-02-01 — User approved expanding advanced-memory with local GPU features while keeping 100% offline (no cloud API calls) (importance: 7) [source: advanced-memory:mem_1769958969528]
+- 2026-02-01 — Advanced-memory expansion plan: Phase 1 LLM scoring (phi-3.5/qwen2.5), Phase 2 Whisper audio transcription, Phase 3 RAG Q&A, Phase 4 summarization, Phase 5 entity extraction (importance: 7) [source: advanced-memory:mem_1769958969511]
+- 2026-02-01 — Whisper transcription service being built - GPU-accelerated audio-to-text using faster-whisper, will auto-store transcriptions as memories (importance: 8) [source: advanced-memory:mem_1769958969495]
