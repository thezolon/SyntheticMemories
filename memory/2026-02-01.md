# 2026-02-01

## Morning

- System updates: Mesa graphics drivers, npm v11.8.0
- Restarted OpenClaw gateway after updates
- Discussed 3CX VoIP project (shelved for later - see notes below)

## 3CX VoIP Project Idea

**Context:** User has a 3CX cloud account and wants to self-host it locally in Docker. Also has a Google Voice number.

**Goal:** Integrate 3CX with PSTN calling cheaply, potentially build a skill for programmatic control.

**Options discussed:**
1. **Hybrid approach (recommended):** 
   - Add cheap SIP trunk (Telnyx ~$2/mo or VoIP.ms ~$1/mo)
   - Forward Google Voice to SIP number for inbound
   - Use SIP for outbound
   - Total cost: ~$3-5/month

2. **Hardware bridge:** Obihai/Grandstream adapter ($40-50 one-time) to connect GV to 3CX via SIP
   - Risk: Google breaks compatibility periodically

3. **Internal-only:** Skip PSTN, use 3CX for extensions/intercom only

**Potential use cases:**
- Advanced call routing/IVR
- Programmatic call handling (I could answer/route calls)
- Integration with home automation
- Call logging to memory
- SMS from chat

**Status:** Shelved for later exploration

## Advanced Memory Skill - ✅ COMPLETE!

**What we built:** Offline semantic memory system for OpenClaw with:
- LanceDB vector storage (embedded, no cloud)
- Ollama embeddings (nomic-embed-text model, fully offline)
- Importance scoring (auto-curate what matters)
- Three-tier hierarchy (Global → User → Session)

**Location:** `~/.openclaw/workspace/skills/advanced-memory/`

**GitHub:** https://github.com/thezolon/openclaw-advanced-memory (private)

**Architecture:**
```
FastAPI Service (Docker)
  ↓
LanceDB (vector database)
  ↓
Ollama (local embeddings via nomic-embed-text)
  ↓
CLI scripts (store/recall/curate)
```

**Status:** ✅ FULLY WORKING

**Testing results:**
- Store: ✅ Working perfectly
- Recall: ✅ Semantic search operational
- Example: "design preferences" → found "User prefers dark themes" (similarity: 452.6)
- Example: "VoIP projects" → found "User wants to self-host 3CX for VoIP" (similarity: 469.8)

**How to use:**
```bash
# Store a memory
advanced-memory store "User fact" --tier user

# Semantic recall
advanced-memory recall "what do I know about X?"

# Auto-curate daily logs to MEMORY.md
advanced-memory curate --from memory/2026-02-01.md --threshold 7

# Check status
advanced-memory status
```

**Technical challenges solved:**
- Float32 type conversion (LanceDB requirement)
- PyArrow schema definition for vector columns
- Ollama embedding integration
- Docker build caching issues

**Why this matters:** 
- Gives me persistent, searchable memory that survives OpenClaw updates
- Better than manually updating MEMORY.md
- 100% offline, no API costs
- Can be called from OpenClaw workflows via `exec`

**Next steps:**
- Integrate with heartbeat for auto-curation
- Test curate command on daily logs
- Build analytics/visualization (optional)

---

**Session notes:** Good morning session - maintenance + project planning. Advanced memory skill is 90% done, just needs final type conversion fix.
