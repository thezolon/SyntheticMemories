# Roadmap

## Vision

Build the most privacy-respecting, powerful, and personal cognitive memory system that runs entirely on your local machine.

## Phases

### Phase 0: Foundation (Current)
**Goal**: Project setup and core architecture

- [x] Repository setup
- [x] Documentation structure
- [ ] Development environment
- [ ] CI/CD pipeline
- [ ] Testing framework

**Timeline**: Week 1

---

### Phase 1: MVP - Basic Memory System
**Goal**: Store and retrieve text memories with semantic search

**Features**:
- âœ¨ Text ingestion (CLI)
- âœ¨ Semantic search with embeddings
- âœ¨ Simple query interface
- âœ¨ Local storage (Lance)
- âœ¨ Basic LLM integration

**Deliverables**:
- CLI tool for ingestion: `memory add "I met John at the coffee shop"`
- CLI tool for retrieval: `memory search "where did I meet John?"`
- ~1000 memories without performance degradation
- Basic summarization of results

**Success Criteria**:
- Query latency < 2s
- Relevant results in top 5
- Zero external API calls

**Timeline**: Weeks 2-4

---

### Phase 2: Enhanced Retrieval
**Goal**: Improve search quality and add context

**Features**:
- ðŸ” Hybrid search (vector + keyword)
- ðŸ” Temporal filtering (date ranges)
- ðŸ” Metadata tagging and filtering
- ðŸ” Result reranking
- ðŸ” Query expansion

**Deliverables**:
- Advanced query syntax: `memory search "projects" --after 2026-01-01 --tag work`
- Relevance feedback mechanism
- Cross-encoder reranking
- Better result explanations

**Timeline**: Weeks 5-7

---

### Phase 3: Audio & Multi-Modal
**Goal**: Support audio transcription and document ingestion

**Features**:
- ðŸŽ¤ Audio transcription (Whisper)
- ðŸ“„ Document parsing (PDF, DOCX, Markdown)
- ðŸ–¼ï¸ Image descriptions (optional, if model available)
- ðŸ”— URL content extraction

**Deliverables**:
- `memory add --audio meeting.mp3`
- `memory add --file report.pdf`
- Automatic chunking for long documents
- Timestamp-aware search for audio

**Timeline**: Weeks 8-10

---

### Phase 4: Intelligent Features
**Goal**: Proactive and context-aware memory assistance

**Features**:
- ðŸ§  Memory consolidation (auto-summarization)
- ðŸ§  Concept extraction and linking
- ðŸ§  Temporal reasoning ("what happened before X?")
- ðŸ§  Memory suggestions ("you might want to remember this")
- ðŸ§  Conflict detection ("this contradicts earlier memory")

**Deliverables**:
- Background consolidation service
- Knowledge graph visualization
- Smart reminders
- Memory health dashboard

**Timeline**: Weeks 11-14

---

### Phase 5: Web UI & API
**Goal**: Better user experience and integration options

**Features**:
- ðŸ–¥ï¸ Web-based UI for browsing memories
- ðŸ–¥ï¸ Timeline view
- ðŸ–¥ï¸ Graph visualization
- ðŸ”Œ REST API for external tools
- ðŸ”Œ Plugin system

**Deliverables**:
- Local web server (FastAPI)
- Interactive memory explorer
- API documentation
- Example integrations (Obsidian, Logseq)

**Timeline**: Weeks 15-18

---

### Phase 6: Advanced Models & Performance
**Goal**: Support larger models and scale to 100k+ memories

**Features**:
- âš¡ GPU acceleration
- âš¡ Model quantization options
- âš¡ Distributed embeddings
- âš¡ Incremental indexing
- âš¡ Advanced caching

**Deliverables**:
- Support for larger LLMs (7B+)
- Sub-second queries at 100k memories
- Configurable model selection
- Performance benchmarking suite

**Timeline**: Weeks 19-22

---

### Phase 7: Polish & Stability
**Goal**: Production-ready for daily use

**Features**:
- ðŸ›¡ï¸ Comprehensive error handling
- ðŸ›¡ï¸ Data recovery tools
- ðŸ›¡ï¸ Encrypted storage
- ðŸ›¡ï¸ Backup/restore utilities
- ðŸ›¡ï¸ Migration tools

**Deliverables**:
- 90%+ test coverage
- Documentation for all features
- Installation guides (Linux, macOS, Windows)
- Common issue troubleshooting

**Timeline**: Weeks 23-26

---

## Future Exploration (Post-v1.0)

### Collaborative Memory (Privacy-Preserving)
- Shared memory spaces with E2E encryption
- Selective sharing of specific memories
- Collaborative knowledge graphs

### Mobile Support
- iOS/Android apps
- Local-first sync protocol
- Offline-capable mobile clients

### Advanced AI Features
- Fine-tuned personal models
- Reinforcement learning from feedback
- Predictive memory retrieval
- Conversational memory interface

### Integration Ecosystem
- Browser extension (save browsing context)
- Calendar integration
- Email parsing
- Note-taking app plugins
- IDE extensions

### Research Directions
- Memory decay models (temporal weighting)
- Episodic vs semantic memory separation
- Cross-lingual memory support
- Privacy-preserving memory analytics

---

## Milestones

| Milestone | Target Date | Status |
|-----------|-------------|--------|
| **v0.1** - MVP | Week 4 | ðŸ”„ In Progress |
| **v0.2** - Enhanced Retrieval | Week 7 | ðŸ“‹ Planned |
| **v0.3** - Multi-Modal | Week 10 | ðŸ“‹ Planned |
| **v0.4** - Intelligent Features | Week 14 | ðŸ“‹ Planned |
| **v0.5** - Web UI & API | Week 18 | ðŸ“‹ Planned |
| **v0.6** - Performance | Week 22 | ðŸ“‹ Planned |
| **v1.0** - Production Ready | Week 26 | ðŸŽ¯ Goal |

---

## Contribution Focus Areas

We welcome contributions in these areas:

1. **Core Engine**: Embedding models, vector stores, retrieval algorithms
2. **UX/UI**: CLI improvements, web interface, visualizations
3. **Integrations**: Plugins for popular tools (Obsidian, Notion, etc.)
4. **Testing**: Unit tests, integration tests, performance benchmarks
5. **Documentation**: Tutorials, guides, API docs
6. **Models**: Quantization, optimization, fine-tuning
7. **Security**: Encryption, audit, privacy features

---

## Decision Log

### Why Lance over FAISS?
- Modern columnar format (better for mixed data types)
- Built-in versioning
- Better Python integration
- Active development

### Why llama.cpp over Ollama?
- Lower-level control
- Better for embedding in applications
- More deployment flexibility
- Ollama can be added as an alternative backend

### Why not cloud-first?
- Privacy is core to the mission
- Local-first ensures full control
- No dependency on external services
- Better for sensitive personal data

---

**This roadmap is a living document.** Priorities may shift based on user feedback and technical discoveries.

Last updated: 2026-02-02
